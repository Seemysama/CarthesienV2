#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de nettoyage NLP pour les pros/cons des v√©hicules.

Objectif: Transformer des retours "forum-style" en arguments professionnels.

Transformations appliqu√©es:
- Suppression des √©motions parasites ("j'adore", "super content", etc.)
- Normalisation orthographique et grammaticale
- Extraction des arguments factuels
- D√©duplication intelligente (s√©mantique)
- Standardisation du ton (professionnel)

Usage:
    python -m scripts.clean_text_data

Auteur: Car-thesien
Date: 2025
"""

import re
import logging
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import json
from collections import Counter

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# =============================================================================
# DICTIONNAIRES DE NETTOYAGE
# =============================================================================

# Patterns √©motionnels √† supprimer ou transformer
EMOTIONAL_PATTERNS = [
    # Superlatifs excessifs
    (r"\b(super|trop|vraiment|vachement|carr√©ment|franchement)\s+(bien|bon|content|satisfait|top)\b", "satisfaisant"),
    (r"\bj'adore\b", "appr√©ci√©"),
    (r"\bje kiffe\b", "appr√©ci√©"),
    (r"\bc'est top\b", "satisfaisant"),
    (r"\bc'est g√©nial\b", "excellent"),
    (r"\bc'est le feu\b", "performant"),
    (r"\bau top\b", "de qualit√©"),
    
    # Expressions n√©gatives excessives
    (r"\bc'est nul\b", "insuffisant"),
    (r"\bc'est pourri\b", "de mauvaise qualit√©"),
    (r"\bc'est de la merde\b", "de tr√®s mauvaise qualit√©"),
    (r"\b√ßa craint\b", "d√©cevant"),
    (r"\bj'en peux plus\b", "probl√©matique"),
    (r"\b√ßa me so√ªle\b", "contraignant"),
    
    # √âmotions personnelles
    (r"\bje suis (super |tr√®s |vraiment )?(content|satisfait|heureux|ravi)\b", "positif"),
    (r"\bje suis (super |tr√®s |vraiment )?(d√©√ßu|m√©content|frustr√©)\b", "n√©gatif"),
    (r"\bpersonnellement\b", ""),
    (r"\b√† mon avis\b", ""),
    (r"\bpour moi\b", ""),
    (r"\bbon apr√®s\b", "cependant"),
    
    # Ponctuations excessives
    (r"!{2,}", "!"),
    (r"\?{2,}", "?"),
    (r"\.{3,}", "..."),
]

# Abr√©viations et argot √† normaliser
ABBREVIATIONS = {
    "bcp": "beaucoup",
    "pb": "probl√®me",
    "pbs": "probl√®mes",
    "qd": "quand",
    "qq": "quelques",
    "qqn": "quelqu'un",
    "qqch": "quelque chose",
    "tt": "tout",
    "tjs": "toujours",
    "ns": "nous",
    "vs": "vous",
    "pr": "pour",
    "ac": "avec",
    "ds": "dans",
    "ms": "mais",
    "rdv": "rendez-vous",
    "cv": "chevaux",
    "km": "kilom√®tres",
    "conso": "consommation",
    "clim": "climatisation",
    "gps": "GPS",
    "bva": "bo√Æte automatique",
    "bvm": "bo√Æte manuelle",
    "esp": "ESP",
    "abs": "ABS",
    "ct": "contr√¥le technique",
    "cf": "conforme",
    "pneus": "pneumatiques",
    "amort": "amortisseurs",
    "freins": "syst√®me de freinage",
    "embr": "embrayage",
    "volant": "direction",
    "si√®ges": "si√®ges",
    "coffre": "volume de coffre",
    "moteur": "motorisation",
    "boite": "transmission",
    "suspen": "suspensions",
}

# Transformations de qualit√©s (pro)
PRO_TRANSFORMATIONS = {
    # Consommation
    r"(ne |)consomme (pas |peu |rien|quasi rien)": "Faible consommation",
    r"(tr√®s |super |)√©conomique": "Consommation √©conomique",
    r"pas gourmand(e)?": "Consommation ma√Ætris√©e",
    
    # Confort
    r"(tr√®s |super |vraiment |)confortable": "Bon niveau de confort",
    r"on est bien (assis|install√©)": "Confort des si√®ges",
    r"silence de roulement": "Insonorisation soign√©e",
    r"(bonne|super) clim": "Climatisation efficace",
    
    # Espace
    r"(tr√®s |super |bien )spacieux": "Habitabilit√© g√©n√©reuse",
    r"(grand|gros) coffre": "Volume de coffre important",
    r"(beaucoup de |)place (√† l'|)arri√®re": "Places arri√®re confortables",
    
    # Fiabilit√©
    r"(aucun|pas de) (souci|probl√®me|panne)": "Fiabilit√© exemplaire",
    r"(jamais |)tomb√© en panne": "Aucune panne signal√©e",
    r"(tr√®s |super |)fiable": "Bonne fiabilit√©",
    r"(solide|robuste)": "Construction robuste",
    
    # Agr√©ment de conduite
    r"(sympa|agr√©able|plaisant) √† conduire": "Agr√©ment de conduite",
    r"(bonne|super) tenue de route": "Comportement routier sain",
    r"(nerveux|p√™chu|dynamique)": "Motorisation r√©active",
    r"(direction|volant) pr√©cis(e)?": "Direction pr√©cise",
    
    # Budget
    r"(pas |peu )cher en entretien": "Co√ªts d'entretien contenus",
    r"(bonne|super) cote (√† la revente)?": "Valeur r√©siduelle correcte",
    r"(pi√®ces|entretien) pas cher": "Pi√®ces d√©tach√©es abordables",
    
    # Design
    r"(belle|jolie|super) (gueule|ligne|allure)": "Design r√©ussi",
    r"(finition|int√©rieur) (soign√©|quali|qualit√©)": "Finition de qualit√©",
}

# Transformations de d√©fauts (con)
CON_TRANSFORMATIONS = {
    # Consommation
    r"(consomme|boit) (beaucoup|pas mal|trop)": "Consommation √©lev√©e",
    r"(tr√®s |super |)gourmand(e)?": "Consommation excessive",
    r"(essence|diesel) √ßa fait mal": "Budget carburant important",
    
    # Fiabilit√©
    r"(souvent|r√©guli√®rement) en panne": "Fiabilit√© al√©atoire",
    r"(probl√®me|souci) (de |d')(\w+)": r"Probl√®me de \3 signal√©",
    r"(√©lectronique|√©lectrique) capricieu(x|se)": "√âlectronique perfectible",
    r"(rouille|corrosion)": "Sensibilit√© √† la corrosion",
    
    # Co√ªts
    r"(entretien|r√©parations?) (cher|co√ªteux|hors de prix)": "Co√ªts d'entretien √©lev√©s",
    r"(pi√®ces|r√©vision) (ch√®res?|hors de prix)": "Pi√®ces d√©tach√©es on√©reuses",
    r"(assurance|taxe) (ch√®re|√©lev√©e)": "Fiscalit√© automobile √©lev√©e",
    
    # Confort
    r"(si√®ges?|suspension) (dur|ferme|raide)": "Suspensions fermes",
    r"(bruit|bruyant) (moteur|roulement)": "Insonorisation perfectible",
    r"(mal|peu) insonoris√©": "Isolation phonique √† am√©liorer",
    r"(clim|chauffage) (faible|insuffisant)": "Climatisation √† am√©liorer",
    
    # Espace
    r"(petit|√©troit|√©triqu√©) coffre": "Volume de coffre limit√©",
    r"(peu de|manque de) place (arri√®re)?": "Habitabilit√© arri√®re limit√©e",
    r"(manque|pas assez) de rangements?": "Rangements insuffisants",
    
    # Conduite
    r"(mou|sous-motoris√©|manque de p√™che)": "Motorisation juste",
    r"(direction|volant) (flou|impr√©cis)": "Direction peu pr√©cise",
    r"(mauvaise|pas terrible) tenue de route": "Comportement routier perfectible",
    r"(bo√Æte|bva) (lente|molle|saccad√©e)": "Transmission √† am√©liorer",
}

# Patterns de phrases inutiles √† supprimer
USELESS_PATTERNS = [
    r"^(bon(jour)?|salut|hello|coucou)[\s,\.!]*",
    r"^(voil√†|en (gros|bref|r√©sum√©))[\s,\.!]*",
    r"^(donc|alors|bref|du coup)[\s,\.!]*",
    r"[\s,\.]*(voil√†|bref|en gros)[\s\.!]*$",
    r"^(pour info|√† savoir)[\s:,\.!]*",
    r"^(j'ai|on a) (achet√©|pris) (cette|cette voiture|ce|un|une)[\s\w]*[\s,\.]",
    r"^(√ßa fait|il y a) \d+ (ans?|mois)[\s\w]*[\s,\.]",
    r"^(apr√®s|depuis) \d+ (km|kilom√®tres)[\s\w]*[\s,\.]",
]


# =============================================================================
# FONCTIONS DE NETTOYAGE
# =============================================================================

def clean_emotional_content(text: str) -> str:
    """Supprime ou transforme le contenu √©motionnel excessif."""
    result = text
    for pattern, replacement in EMOTIONAL_PATTERNS:
        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)
    return result.strip()


def expand_abbreviations(text: str) -> str:
    """√âtend les abr√©viations en mots complets."""
    result = text
    for abbrev, full in ABBREVIATIONS.items():
        # Assure que c'est un mot entier (pas partie d'un mot)
        pattern = r'\b' + re.escape(abbrev) + r'\b'
        result = re.sub(pattern, full, result, flags=re.IGNORECASE)
    return result


def remove_useless_phrases(text: str) -> str:
    """Supprime les phrases sans valeur informative."""
    result = text
    for pattern in USELESS_PATTERNS:
        result = re.sub(pattern, '', result, flags=re.IGNORECASE)
    return result.strip()


def apply_pro_transformations(text: str) -> str:
    """Applique les transformations sp√©cifiques aux points positifs."""
    result = text
    for pattern, replacement in PRO_TRANSFORMATIONS.items():
        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)
    return result


def apply_con_transformations(text: str) -> str:
    """Applique les transformations sp√©cifiques aux points n√©gatifs."""
    result = text
    for pattern, replacement in CON_TRANSFORMATIONS.items():
        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)
    return result


def normalize_punctuation(text: str) -> str:
    """Normalise la ponctuation et les espaces."""
    # Supprimer les espaces multiples
    result = re.sub(r'\s+', ' ', text)
    # Supprimer les espaces avant la ponctuation
    result = re.sub(r'\s+([.,!?;:])', r'\1', result)
    # Ajouter espace apr√®s la ponctuation
    result = re.sub(r'([.,!?;:])([A-Za-z√Ä-√ø])', r'\1 \2', result)
    # Majuscule en d√©but
    if result:
        result = result[0].upper() + result[1:] if len(result) > 1 else result.upper()
    # Point final si manquant
    if result and result[-1] not in '.!?':
        result += '.'
    return result.strip()


def clean_single_text(text: str, is_pro: bool = True) -> str:
    """
    Nettoie un texte unique (qualit√© ou d√©faut).
    
    Args:
        text: Le texte √† nettoyer
        is_pro: True si c'est une qualit√©, False si c'est un d√©faut
        
    Returns:
        Texte nettoy√© et professionnalis√©
    """
    if not text or not isinstance(text, str):
        return ""
    
    # Pipeline de nettoyage
    result = text.strip()
    result = remove_useless_phrases(result)
    result = expand_abbreviations(result)
    result = clean_emotional_content(result)
    
    # Transformations sp√©cifiques
    if is_pro:
        result = apply_pro_transformations(result)
    else:
        result = apply_con_transformations(result)
    
    result = normalize_punctuation(result)
    
    # Filtrer si trop court (< 10 caract√®res) ou vide apr√®s nettoyage
    if len(result) < 10:
        return ""
    
    return result


def deduplicate_semantic(items: List[str]) -> List[str]:
    """
    D√©duplique les items bas√© sur la similarit√© s√©mantique.
    
    Utilise une approche simple bas√©e sur les mots-cl√©s.
    """
    if not items:
        return []
    
    # Extraire les mots-cl√©s significatifs de chaque item
    def extract_keywords(text: str) -> set:
        # Mots vides √† ignorer
        stopwords = {
            'le', 'la', 'les', 'un', 'une', 'des', 'de', 'du', '√†', 'au', 'aux',
            'et', 'ou', 'mais', 'car', 'donc', 'or', 'ni', 'que', 'qui', 'quoi',
            'ce', 'cette', 'ces', 'son', 'sa', 'ses', 'mon', 'ma', 'mes',
            'tr√®s', 'peu', 'trop', 'assez', 'bien', 'bon', 'bonne',
            'est', 'sont', 'a', 'ont', 'fait', '√™tre', 'avoir',
        }
        words = set(re.findall(r'\b[a-z√†√¢√§√©√®√™√´√Ø√Æ√¥√π√ª√º√ß]{3,}\b', text.lower()))
        return words - stopwords
    
    # Garder uniquement les items avec des keywords uniques
    seen_keywords: List[set] = []
    unique_items = []
    
    for item in items:
        keywords = extract_keywords(item)
        
        # V√©rifier la similarit√© avec les items d√©j√† vus
        is_duplicate = False
        for seen in seen_keywords:
            # Si plus de 60% des mots-cl√©s sont communs, c'est un doublon
            if seen and keywords:
                overlap = len(keywords & seen) / min(len(keywords), len(seen))
                if overlap > 0.6:
                    is_duplicate = True
                    break
        
        if not is_duplicate and keywords:
            unique_items.append(item)
            seen_keywords.append(keywords)
    
    return unique_items


def clean_pros_cons_list(items: List[str], is_pro: bool = True) -> List[str]:
    """
    Nettoie une liste de qualit√©s ou d√©fauts.
    
    Args:
        items: Liste des items √† nettoyer
        is_pro: True pour qualit√©s, False pour d√©fauts
        
    Returns:
        Liste nettoy√©e et d√©dupliqu√©e
    """
    if not items:
        return []
    
    # Nettoyer chaque item
    cleaned = [clean_single_text(item, is_pro) for item in items]
    
    # Filtrer les vides
    cleaned = [item for item in cleaned if item]
    
    # D√©dupliquer
    cleaned = deduplicate_semantic(cleaned)
    
    return cleaned


# =============================================================================
# PROCESSING MONGODB
# =============================================================================

def process_mongodb_collection():
    """
    Traite la collection vehicle_stats dans MongoDB.
    
    Nettoie les champs 'qualites' et 'defauts' de chaque document.
    """
    try:
        from pymongo import MongoClient
        
        # Connexion MongoDB
        client = MongoClient("mongodb://localhost:27017/")
        db = client['carthesienDB']
        collection = db['vehicle_stats']
        
        logger.info("üìä D√©but du nettoyage des donn√©es textuelles...")
        
        # Stats
        total_docs = collection.count_documents({})
        processed = 0
        modified = 0
        
        logger.info(f"   Documents √† traiter: {total_docs}")
        
        # Traitement par batch
        batch_size = 100
        cursor = collection.find({}, {'_id': 1, 'qualites': 1, 'defauts': 1, 'marque': 1, 'modele': 1})
        
        for doc in cursor:
            processed += 1
            doc_id = doc['_id']
            qualites = doc.get('qualites', [])
            defauts = doc.get('defauts', [])
            
            # Nettoyer
            new_qualites = clean_pros_cons_list(qualites, is_pro=True)
            new_defauts = clean_pros_cons_list(defauts, is_pro=False)
            
            # V√©rifier si des modifications ont √©t√© faites
            qualites_changed = qualites != new_qualites
            defauts_changed = defauts != new_defauts
            
            if qualites_changed or defauts_changed:
                update = {}
                if qualites_changed:
                    update['qualites'] = new_qualites
                    update['qualites_original'] = qualites  # Backup
                if defauts_changed:
                    update['defauts'] = new_defauts
                    update['defauts_original'] = defauts  # Backup
                
                collection.update_one({'_id': doc_id}, {'$set': update})
                modified += 1
                
                if modified <= 5:  # Log les 5 premiers exemples
                    logger.info(f"   Exemple: {doc.get('marque', '?')} {doc.get('modele', '?')}")
                    if qualites_changed:
                        logger.info(f"     Qualit√©s: {len(qualites)} ‚Üí {len(new_qualites)}")
                    if defauts_changed:
                        logger.info(f"     D√©fauts: {len(defauts)} ‚Üí {len(new_defauts)}")
            
            # Progress
            if processed % 500 == 0:
                logger.info(f"   Progression: {processed}/{total_docs} ({modified} modifi√©s)")
        
        logger.info(f"‚úÖ Nettoyage termin√©: {modified}/{total_docs} documents modifi√©s")
        
        client.close()
        return {'total': total_docs, 'modified': modified}
        
    except ImportError:
        logger.error("‚ùå pymongo non install√©. Installation: pip install pymongo")
        return None
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du traitement MongoDB: {e}")
        return None


def process_json_files():
    """
    Traite les fichiers JSON dans data/avis_auto/.
    
    Nettoie les champs 'qualites' et 'defauts' de chaque fichier.
    """
    data_dir = Path(__file__).parent.parent / 'data' / 'avis_auto'
    
    if not data_dir.exists():
        logger.warning(f"R√©pertoire non trouv√©: {data_dir}")
        return None
    
    logger.info(f"üìÇ Traitement des fichiers JSON dans {data_dir}")
    
    total_files = 0
    modified_files = 0
    
    for json_file in data_dir.glob('*.json'):
        total_files += 1
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            modified = False
            
            # Traiter les avis
            if 'avis' in data and isinstance(data['avis'], list):
                for avis in data['avis']:
                    if 'qualites' in avis:
                        original = avis['qualites']
                        cleaned = clean_pros_cons_list(original, is_pro=True)
                        if original != cleaned:
                            avis['qualites'] = cleaned
                            avis['qualites_original'] = original
                            modified = True
                    
                    if 'defauts' in avis:
                        original = avis['defauts']
                        cleaned = clean_pros_cons_list(original, is_pro=False)
                        if original != cleaned:
                            avis['defauts'] = cleaned
                            avis['defauts_original'] = original
                            modified = True
            
            # Traiter les qualites/defauts globaux
            if 'qualites' in data:
                original = data['qualites']
                cleaned = clean_pros_cons_list(original, is_pro=True)
                if original != cleaned:
                    data['qualites'] = cleaned
                    data['qualites_original'] = original
                    modified = True
            
            if 'defauts' in data:
                original = data['defauts']
                cleaned = clean_pros_cons_list(original, is_pro=False)
                if original != cleaned:
                    data['defauts'] = cleaned
                    data['defauts_original'] = original
                    modified = True
            
            if modified:
                # Sauvegarder le fichier modifi√©
                with open(json_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                modified_files += 1
                logger.info(f"   ‚úì {json_file.name}")
                
        except json.JSONDecodeError as e:
            logger.warning(f"   ‚ö† Erreur JSON dans {json_file.name}: {e}")
        except Exception as e:
            logger.warning(f"   ‚ö† Erreur pour {json_file.name}: {e}")
    
    logger.info(f"‚úÖ Fichiers JSON trait√©s: {modified_files}/{total_files} modifi√©s")
    return {'total': total_files, 'modified': modified_files}


# =============================================================================
# TESTS
# =============================================================================

def run_tests():
    """Ex√©cute des tests de validation du nettoyage."""
    logger.info("üß™ Ex√©cution des tests de nettoyage...")
    
    test_cases = [
        # (input, expected_contains, is_pro)
        ("J'adore cette voiture, super confortable!", "confort", True),
        ("Consomme pas mal, √ßa fait mal au portefeuille", "Consommation", False),
        ("Bcp de place, coffre √©norme, tt le monde est bien!", "Volume de coffre", True),
        ("C'est nul, tjs en panne, pb d'√©lectronique", "Fiabilit√©", False),
        ("Voil√†, donc en gros c'est super top la caisse!", "satisfaisant", True),
        ("le moteur est nerveux et la direction pr√©cise", "r√©active", True),
        ("entretien cher et pi√®ces hors de prix", "Co√ªts d'entretien", False),
    ]
    
    passed = 0
    failed = 0
    
    for input_text, expected, is_pro in test_cases:
        result = clean_single_text(input_text, is_pro)
        if expected.lower() in result.lower():
            passed += 1
            logger.info(f"   ‚úì '{input_text[:30]}...' ‚Üí '{result}'")
        else:
            failed += 1
            logger.warning(f"   ‚úó '{input_text[:30]}...' ‚Üí '{result}' (attendu: contient '{expected}')")
    
    logger.info(f"üìä Tests: {passed} pass√©s, {failed} √©chou√©s")
    return passed, failed


# =============================================================================
# MAIN
# =============================================================================

def main():
    """Point d'entr√©e principal."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Nettoyage NLP des donn√©es textuelles')
    parser.add_argument('--test', action='store_true', help='Ex√©cuter les tests')
    parser.add_argument('--mongodb', action='store_true', help='Traiter MongoDB vehicle_stats')
    parser.add_argument('--json', action='store_true', help='Traiter les fichiers JSON')
    parser.add_argument('--all', action='store_true', help='Tout traiter')
    
    args = parser.parse_args()
    
    logger.info("=" * 60)
    logger.info("üßπ SCRIPT DE NETTOYAGE NLP - Car-thesien")
    logger.info("=" * 60)
    
    # Si aucun argument, tout faire par d√©faut
    if not (args.test or args.mongodb or args.json or args.all):
        args.all = True
    
    if args.test or args.all:
        run_tests()
        print()
    
    if args.json or args.all:
        process_json_files()
        print()
    
    if args.mongodb or args.all:
        process_mongodb_collection()
        print()
    
    logger.info("=" * 60)
    logger.info("‚úÖ Nettoyage termin√©")
    logger.info("=" * 60)


if __name__ == '__main__':
    main()
